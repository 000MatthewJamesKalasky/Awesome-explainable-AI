# Awesome-explainable-AI
A  collection of research materials on explainable AI
![Open the BlackBox](https://github.com/iversonicter/awesome-explainable-AI/blob/master/fig/blackbox.png)

## Survey
[A survey of methods for explaining black box models](http://arxiv.org/abs/1802.01933)

[A Survey on Explainable Artificial Intelligence (XAI): Towards Medical XAI](http://arxiv.org/abs/1907.07374)

[Explaining Explanations: An Overview of Interpretability of Machine Learning](https://arxiv.org/abs/1806.00069)

[Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)](https://ieeexplore.ieee.org/document/8466590/)

[Explainable Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI](http://arxiv.org/abs/1910.10045)


## Books

[Interpretable Machine Learning A Guide for Making Black Box Models Explainable](https://christophm.github.io/interpretable-ml-book/)

[Explainable AI: Interpreting, Explaining and Visualizing Deep Learning](http://link.springer.com/10.1007/978-3-030-28954-6)

## Online Videos

## Courses

[Interpretability and Explainability in Machine Learningï¼Œ Harvard University](https://interpretable-ml-class.github.io/)

## Papers

[How important is a neuron?](http://arxiv.org/abs/1805.12233), ICLR 2019

[Sanity checks for saliency maps](http://arxiv.org/abs/1810.03292), NIPS 2018

[Did the Model Understand the Question?](http://arxiv.org/abs/1805.05492), ACL 2018

Neuron Integrated Gradients: [Computationally Efficient Measures of Internal Neuron Importance](http://arxiv.org/abs/1807.09946) , preprint 2018

TCAV: [Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)](https://arxiv.org/abs/1711.11279), ICML 2018

[Influence-Directed Explanations for Deep Convolutional Networks](http://arxiv.org/abs/1802.03788), IEEE International Test Conference 2018

Shap: [A unified approach to interpreting model predictions](http://arxiv.org/abs/1705.07874), NIPS 2017

DeepLIFT: [Learning important features through propagating activation differences](http://arxiv.org/abs/1704.02685), ICML 2017


Integrated Gradients: [Axiomatic attribution for deep networks](http://arxiv.org/abs/1703.01365), ICML 2017

SmoothGard: [SmoothGrad: removing noise by adding noise](http://arxiv.org/abs/1706.03825), preprint 2017

Lime: ["Why Should I Trust You?": Explaining the Predictions of Any Classifier](http://arxiv.org/abs/1602.04938), SIGKDD 2016

Grad-CAM: [Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization](http://arxiv.org/abs/1610.02391) IJCV 2016

LRP: [Layer-wise relevance propagation for neural networks with local renormalization layers](http://arxiv.org/abs/1604.00825), ICANN 2016

[Examples are not enough, learn to criticize! Criticism for interpretability](https://papers.nips.cc/paper/6300-examples-are-not-enough-learn-to-criticize-criticism-for-interpretability), NIPS 2016

CAM: [Learning Deep Features for Discriminative Localization](http://arxiv.org/abs/1512.04150), CVPR 2015

ConvNet: [Deep inside convolutional networks: Visualising image classification models and saliency maps](http://arxiv.org/abs/1312.6034), ICLR 2014


## Codes

Captum: [https://github.com/pytorch/captum](https://github.com/pytorch/captum)

SHAP: [https://github.com/slundberg/shap](https://github.com/slundberg/shap)

Lime: [https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)

Pytorch-grad-cam: [https://github.com/jacobgil/pytorch-grad-cam](https://github.com/jacobgil/pytorch-grad-cam)

Keras-grad-cam: [https://github.com/jacobgil/keras-grad-cam](https://github.com/jacobgil/keras-grad-cam)

Grad-cam-Tensorflow: [https://github.com/insikk/Grad-CAM-tensorflow](https://github.com/insikk/Grad-CAM-tensorflow)

Deeplift: [https://github.com/kundajelab/deeplift](https://github.com/kundajelab/deeplift)

Eli5: [https://github.com/TeamHG-Memex/eli5](https://github.com/TeamHG-Memex/eli5)

Skater: [https://github.com/oracle/Skater](https://github.com/oracle/Skater)

PDPbox: [https://github.com/SauceCat/PDPbox](https://github.com/SauceCat/PDPbox)

Alibi: [https://github.com/SeldonIO/alibi](https://github.com/SeldonIO/alibi)

TCAV: [https://github.com/tensorflow/tcav](https://github.com/tensorflow/tcav)

PyCEbox: [https://github.com/AustinRochford/PyCEbox](https://github.com/AustinRochford/PyCEbox)




